{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Graph_convolution.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoVogiatzis/GNN_based_NILM/blob/main/GNN_based_NILM/tree/main/notebooks/Graph_convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqJN0nnHkyWB",
        "outputId": "3440f512-1cdd-491a-de77-33702b334998"
      },
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.1 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHkddIBflBoM"
      },
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Dataset, Data\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7XtJNgrlAWw",
        "outputId": "6e60d264-74de-41a8-90e8-70cc2cfa4678"
      },
      "source": [
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 1.10.0+cu111\n",
            "Cuda available: True\n",
            "Torch geometric version: 2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "gu9NTNR-73SM",
        "outputId": "83a2025d-5442-4a82-820c-b1be4c9b82c3"
      },
      "source": [
        "import io\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2cb50494-ed90-4cef-8eac-9f57a97e36db\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2cb50494-ed90-4cef-8eac-9f57a97e36db\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dishwaser_20.graphml to dishwaser_20.graphml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyOHKJb8bWRg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "fde0176e-63e8-4455-e3d5-5f80a951ece4"
      },
      "source": [
        "G = nx.read_graphml('data/raw/dishwaser_20.graphml')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-fb0b2a4ae77b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_graphml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/raw/dishwaser_20.graphml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__wrapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0margmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0;31m# standard function-wrapping stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36margmap_read_graphml_1\u001b[0;34m(path, node_type, edge_key_type, force_multigraph)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplitext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dispatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/raw/dishwaser_20.graphml'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KojcJ7SWbmCD"
      },
      "source": [
        "G.nodes(data=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMphwXgm_j0k"
      },
      "source": [
        "[int(i) for i in G.nodes()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NDyBkICBrcq"
      },
      "source": [
        "class NilmDataset(Dataset):\n",
        "    def __init__(self, root, filename, test=False, transform=None, pre_transform=None):\n",
        "        \"\"\"2\n",
        "        root = Where the dataset should be stored. This folder is split \n",
        "        into raw_dir (downloaded dataset) and processed_dir (processed data).\n",
        "        \"\"\"\n",
        "        self.test = test\n",
        "        self.filename = filename\n",
        "        super(NilmDataset, self).__init__(root, transform, pre_transform)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
        "            (The download func. is not implemented here)\n",
        "        \"\"\"\n",
        "        return self.filename\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        \"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\n",
        "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
        "\n",
        "        if self.test:\n",
        "            return [f'data_test_{i}.pt' for i in list(self.data.index)]\n",
        "        else:\n",
        "            return [f'data_{i}.pt' for i in list(self.data.index)]\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        self.G = nx.read_graphml(self.raw_paths[0])\n",
        "        print(len(self.G.nodes), len(self.G.edges))\n",
        "        # TODO: read graphs below\n",
        "            # Get node features\n",
        "        node_feats = self._get_node_features(self.G)\n",
        "            # Get edge features\n",
        "        edge_feats = self._get_edge_features(self.G)\n",
        "            # Get adjacency info\n",
        "        edge_index = self._get_adjacency_info(self.G)\n",
        "            # Get labels info\n",
        "        labels = self._get_labels(nx.get_node_attributes(self.G, 'state'))  # pass label here. E.g. if it is a column for this graph it could be graph_csv['label']\n",
        "\n",
        "            # Create data object\n",
        "        # self.data = Data(x=node_feats, edge_index=edge_index, y=labels)\n",
        "        \n",
        "        self.data = Data(x=node_feats, edge_index=edge_index, \n",
        "                         edge_attr=edge_feats, y=labels, \n",
        "                        #  train_mask=[2000], test_mask=[2000]\n",
        "                         )\n",
        "        \n",
        "\n",
        "        self.num_classes = 2\n",
        "\n",
        "        nodes = np.asarray([int(i) for i in self.G.nodes()]).astype(np.int64)\n",
        "        node_labels = np.asarray([int(G.nodes[i]['state']) for i in self.G.nodes]).astype(np.int64)\n",
        "        # splitting the data into train, validation and test\n",
        "        X_train, X_test, y_train, y_test = train_test_split(pd.Series(nodes), \n",
        "                                                    pd.Series(node_labels),\n",
        "                                                    test_size=0.30, \n",
        "                                                    random_state=42)\n",
        "        n_nodes = self.G.number_of_nodes()\n",
        "        # create train and test masks for data\n",
        "        self.train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        print(self.train_mask)\n",
        "        self.test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        self.train_mask[X_train.index] = True\n",
        "        self.test_mask[X_test.index] = True\n",
        "        self.data['train_mask'] = train_mask\n",
        "        self.data['test_mask'] = test_mask        \n",
        "        self.data, self.slices = self.collate([data])\n",
        "        \n",
        "        if self.test:\n",
        "          torch.save(self.data, os.path.join(self.processed_dir, 'data_test_0.pt'))\n",
        "        else:\n",
        "          torch.save(self.data, os.path.join(self.processed_dir, 'data_0.pt'))\n",
        "\n",
        "    def _get_node_features(self, graph):\n",
        "        \"\"\"\n",
        "        This will return a matrix / 2d array of the shape\n",
        "        [Number of Nodes, Node Feature size]\n",
        "\n",
        "        We could also use torch_geometric.from_networkx to create a Data object\n",
        "        with both adjacency and features, but instead we do it manually here\n",
        "        \"\"\"\n",
        "        all_node_feats = list(nx.get_node_attributes(graph, 'drift').values())\n",
        "\n",
        "        all_node_feats = np.asarray(all_node_feats)\n",
        "        all_node_feats = all_node_feats.reshape((-1, 1))\n",
        "        return torch.tensor(all_node_feats, dtype=torch.float)\n",
        "\n",
        "    def _get_edge_features(self, graph):\n",
        "      \"\"\" This will return a matirx with the gaussian filter kernel of all \n",
        "          edges\n",
        "      \"\"\"\n",
        "      all_edge_feats = []\n",
        "      for e in graph.edges(data=True):\n",
        "        all_edge_feats += [[e[2]['gaussian_kernel']], [e[2]['gaussian_kernel']]]\n",
        "\n",
        "      return torch.tensor(all_edge_feats, dtype=torch.float)\n",
        "\n",
        "    def _get_adjacency_info(self, graph):\n",
        "        \"\"\"\n",
        "        We could also use torch_geometric.from_networkx to create a Data object\n",
        "        with both adjacency and features, but instead we do it manually here\n",
        "        \"\"\"\n",
        "\n",
        "        edge_indices = []\n",
        "        for edge in graph.edges:\n",
        "            i = int(edge[0])  # get source\n",
        "            j = int(edge[1])  # get destination\n",
        "            edge_indices += [[i, j], [j, i]]  # undirected graph\n",
        "\n",
        "        edge_indices = torch.tensor(edge_indices)\n",
        "        edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
        "        return edge_indices\n",
        "\n",
        "    def _get_labels(self, labels):\n",
        "        labels = list(labels.values())\n",
        "        labels = np.asarray(labels)\n",
        "        return torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "    def len(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def get(self, idx):\n",
        "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
        "            - Is not needed for PyG's InMemoryDataset\n",
        "        \"\"\"\n",
        "        if self.test:\n",
        "            data = torch.load(os.path.join(self.processed_dir, f'data_test_{idx}.pt'))\n",
        "        else:\n",
        "            data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "        return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDVCzvTKvS0l"
      },
      "source": [
        "graph_mains_1 = NilmDataset(root='data', filename='dishwaser_20.graphml')\n",
        "print(graph_mains_1.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkFPh2Qa62nP"
      },
      "source": [
        "data.num_classes = 2\n",
        "labels = np.asarray([int(G.nodes[i]['state']) for i in G.nodes]).astype(np.int64)\n",
        "nodes = np.asarray([int(i) for i in G.nodes()]).astype(np.int64)\n",
        "from sklearn.model_selection import train_test_split\n",
        "# splitting the data into train, validation and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(pd.Series(nodes), \n",
        "                                                    pd.Series(labels),\n",
        "                                                    test_size=0.30, \n",
        "                                                    random_state=42)\n",
        "n_nodes = G.number_of_nodes()\n",
        "# create train and test masks for data\n",
        "train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "train_mask[X_train.index] = True\n",
        "test_mask[X_test.index] = True\n",
        "graph_mains_1.data['train_mask'] = train_mask\n",
        "graph_mains_1.data['test_mask'] = test_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7fJac-oBRXr"
      },
      "source": [
        "graph_mains_1.data.train_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34hKIWp3AIFS"
      },
      "source": [
        "# graph_mains_1.data, graph_mains_1.slices = graph_mains_1.collate([graph_mains_1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB9SlDioLY2y"
      },
      "source": [
        "data = graph_mains_1.data\n",
        "print(data)\n",
        "print('==============================================================')\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "# print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "# print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "# print(f'Is undirected: {data.is_undirected()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vDLLp4ILymm"
      },
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "edge_index = data.edge_index\n",
        "print(edge_index.t())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x44FWfxi53go"
      },
      "source": [
        "graph_mains_1.data.test_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okJ4EXeQMAjL"
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear, ReLU\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(1234)\n",
        "        self.conv1 = GCNConv(data.num_features, 1)\n",
        "        self.conv2 = GCNConv(1, 1)\n",
        "        # self.conv3 = GCNConv(4, 2)\n",
        "        # self.classifier = Linear(1, 1)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "        \n",
        "        # Apply a final (linear) classifier.\n",
        "        # out = self.classifier(h)\n",
        "\n",
        "        # return h.log_softmax(x, dim=1)\n",
        "        # out, \n",
        "        # F.log_softmax(x, dim=1)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "data =  data.to(device)\n",
        "\n",
        "model = GCN().to(device) \n",
        "# model = GCN()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMZXJMcu4vb2"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "optimizer_name = \"Adam\"\n",
        "lr = 1e-1\n",
        "optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "epochs = 200\n",
        "\n",
        "def train():\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  print(graph_mains_1.train_mask)\n",
        "  F.nll_loss(model()[graph_mains_1.train_mask], graph_mains_1.data.y[graph_mains_1.data.train_mask]).backward()\n",
        "  optimizer.step()\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "  model.eval()\n",
        "  logits = model()\n",
        "  mask1 = data['train_mask']\n",
        "  pred1 = logits[mask1].max(1)[1]\n",
        "  acc1 = pred1.eq(data.y[mask1]).sum().item() / mask1.sum().item()\n",
        "  mask = data['test_mask']\n",
        "  pred = logits[mask].max(1)[1]\n",
        "  acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "  return acc1,acc\n",
        "\n",
        "for epoch in range(1, epochs):\n",
        "  train()\n",
        "\n",
        "train_acc,test_acc = test()\n",
        "\n",
        "print('#' * 70)\n",
        "print('Train Accuracy: %s' %train_acc )\n",
        "print('Test Accuracy: %s' % test_acc)\n",
        "print('#' * 70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R_HRDq99Z3h"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.nn import Node2Vec\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC4lKCQ2kTYD"
      },
      "source": [
        "from torch.nn import Linear, ReLU\n",
        "from torch_geometric.nn import Sequential, GCNConv\n",
        "in_channels = 1\n",
        "out_channels =1\n",
        "model = Sequential('x, edge_index', [\n",
        "    (GCNConv(in_channels, 64), 'x, edge_index -> x'),\n",
        "    ReLU(inplace=True),\n",
        "    (GCNConv(64, 64), 'x, edge_index -> x'),\n",
        "    ReLU(inplace=True),\n",
        "    Linear(64, out_channels),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzSYvz0HrWO7"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZeRlQxHkZWW"
      },
      "source": [
        "loader = model.loader(batch_size=128, shuffle=True, num_workers=4)\n",
        "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYvcFbcUgrsf"
      },
      "source": [
        "labels = np.asarray([G.nodes[i]['state'] for i in G.nodes]).astype(np.int64)\n",
        "\n",
        "# assigning colours to node labels\n",
        "color_map = []\n",
        "for i in labels:\n",
        "    if i == 0:\n",
        "        color_map.append('blue')\n",
        "    else: \n",
        "        color_map.append('red')  \n",
        "\n",
        "# transform the embeddings from 128 dimensions to 2D space\n",
        "m = TSNE(learning_rate=20, random_state=42)\n",
        "tsne_features = m.fit_transform(list(model))\n",
        "\n",
        "# plot the transformed embeddings\n",
        "plt.figure(figsize=(9,6)) \n",
        "plt.scatter(x = tsne_features[:,0], \n",
        "            y = tsne_features[:,1],\n",
        "            c = color_map,\n",
        "            s =600,\n",
        "            alpha=0.6)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}